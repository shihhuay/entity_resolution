{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using python 3\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import jellyfish\n",
    "\n",
    "\"\"\"\n",
    "This assignment can be done in groups of 3 students. Everyone must submit individually.\n",
    "\n",
    "Write down the UNIs of your group (if applicable)\n",
    "\n",
    "Name : Shih Hua Yu\n",
    "Uni  : sy2734\n",
    "\n",
    "Member 2: Chang Ding, cd2959\n",
    "\n",
    "Member 3: Lisa Kim, lk2715\n",
    "\"\"\"\n",
    "def get_matches(locu_train_path, foursquare_train_path, matches_train_path, locu_test_path, foursquare_test_path):\n",
    "    \n",
    "    matching = pd.read_csv(matches_train_path)\n",
    "    locu_train = pd.read_json(locu_train_path)\n",
    "    foursquare_train = pd.read_json(foursquare_train_path)\n",
    "    \n",
    "    def preprocessing(X1, X2, matching):\n",
    "\n",
    "        def normalization(X):\n",
    "            def phonenumber(x):\n",
    "                if x != None:\n",
    "                    new_x = re.sub('[^A-Za-z0-9]+', '', x)\n",
    "                    return new_x\n",
    "            def restaurantname(x):\n",
    "                if x != None:\n",
    "                    new_x = x.lower()\n",
    "                    new_x = re.sub('[^A-Za-z0-9 ]', '', new_x)\n",
    "                    new_x = re.sub(' +', ' ', new_x)\n",
    "                    return new_x\n",
    "            def streetaddress(x):\n",
    "                if x != None:\n",
    "                    new_x = x.lower()\n",
    "                    new_x = re.sub('[^A-Za-z0-9 ]', '', new_x)\n",
    "                    return new_x\n",
    "\n",
    "            X_new = X.copy()\n",
    "            X_new['name'] = X_new['name'].apply(restaurantname)\n",
    "            X_new['phone'] = X_new['phone'].apply(phonenumber)\n",
    "            X_new['street_address'] = X_new['street_address'].apply(streetaddress)\n",
    "\n",
    "            return X_new\n",
    "\n",
    "        def computingdistance(X):\n",
    "            import jellyfish\n",
    "            X['name_jaccard_dis']=X.apply(lambda x: jaccard_distance(set(x['name_x'].split()),\n",
    "                                                                                 set(x['name_y'].split())),axis=1)\n",
    "            X['name_jaro_dis']=X.apply(lambda x: jellyfish.jaro_winkler(x['name_x'],x['name_y']),axis=1)\n",
    "            X['phone_jaro_dis']=X.apply(lambda x: jellyfish.jaro_winkler(x['phone_x'],x['phone_y']),axis=1)\n",
    "            X['poscd_jaro_dis']=X.apply(lambda x: jellyfish.jaro_winkler(x['postal_code_x'],x['postal_code_y']),axis=1)\n",
    "            X['addr_jaro_dis']=X.apply(lambda x: jellyfish.jaro_winkler(x['street_address_x'],x['street_address_y']),axis=1)\n",
    "            X['loc_jaro_dis']=X.apply(lambda x: jellyfish.jaro_winkler(x['locality_x'],x['locality_y']),axis=1)\n",
    "            X['long_dis']=X.apply(lambda x: abs(x['longitude_x']-x['longitude_y']),axis=1)\n",
    "            X['lat_dis']=X.apply(lambda x: abs(x['latitude_x']-x['latitude_y']),axis=1)\n",
    "\n",
    "            return X\n",
    "\n",
    "        X1 = normalization(X1)\n",
    "        X2 = normalization(X2)\n",
    "\n",
    "        # fill missing values with space or mean of the feature depending on variable type\n",
    "        X1['longitude'] = X1['longitude'].fillna(value = X1['longitude'].mean())\n",
    "        X1['latitude'] = X1['latitude'].fillna(value = X1['latitude'].mean())\n",
    "\n",
    "        X2['longitude'] = X2['longitude'].fillna(value = X2['longitude'].mean())\n",
    "        X2['latitude'] = X2['latitude'].fillna(value = X2['latitude'].mean())\n",
    "\n",
    "        X1=X1.drop(columns=['country','website','region'])\n",
    "        X2=X2.drop(columns=['country','website','region'])\n",
    "\n",
    "        #cross join locu and foursquare\n",
    "        X1['key']=1\n",
    "        X2['key']=1\n",
    "        cross_train = X1.merge(X2, on='key',how='outer')\n",
    "\n",
    "        if matching is not None:\n",
    "            #append target column\n",
    "            matching['target']=1\n",
    "            cross_train=cross_train.merge(matching,how='left',left_on=['id_x', 'id_y'],right_on = ['locu_id','foursquare_id'])\n",
    "            cross_train=cross_train.drop(columns=['locu_id','foursquare_id'])\n",
    "            cross_train['missing_phone'] = 0\n",
    "            cross_train.loc[cross_train['phone_x'].isnull() | cross_train['phone_y'].isnull(), 'missing_phone'] = 1\n",
    "            cross_train['missing_phone'] = cross_train['missing_phone'].astype(int)\n",
    "\n",
    "            #for obs not in matching csv, give a target value of 0\n",
    "            cross_train['target']=cross_train['target'].fillna(value=0)\n",
    "            cross_train=cross_train.fillna(value='')\n",
    "\n",
    "            cross_train = computingdistance(cross_train)\n",
    "            cross_train_num = cross_train[['id_x','id_y','name_jaccard_dis','name_jaro_dis','phone_jaro_dis','poscd_jaro_dis',\n",
    "                                       'addr_jaro_dis', 'loc_jaro_dis', 'missing_phone',\n",
    "                                       'long_dis', 'lat_dis','target']]\n",
    "            cross_train_num.target = cross_train_num.target.astype(int)\n",
    "\n",
    "        if matching is None:\n",
    "            cross_train['missing_phone'] = 0\n",
    "            cross_train.loc[cross_train['phone_x'].isnull() | cross_train['phone_y'].isnull(), 'missing_phone'] = 1\n",
    "            cross_train['missing_phone'] = cross_train['missing_phone'].astype(int)\n",
    "            cross_train=cross_train.fillna(value='')\n",
    "            cross_train = computingdistance(cross_train)\n",
    "            cross_train_num = cross_train[['id_x','id_y','name_jaccard_dis','name_jaro_dis','phone_jaro_dis','poscd_jaro_dis',\n",
    "                                   'addr_jaro_dis', 'loc_jaro_dis', 'missing_phone',\n",
    "                                   'long_dis', 'lat_dis']]  \n",
    "        cross_train_num.loc[cross_train_num['missing_phone'] == 1, 'phone_jaro_dis'] = np.nan\n",
    "\n",
    "        return cross_train_num\n",
    "    \n",
    "    cross_train_num = preprocessing(locu_train, foursquare_train, matching)\n",
    "    \n",
    "    #filtering\n",
    "    cross_train_num = cross_train_num.drop(cross_train_num[(cross_train_num['target']==1)\n",
    "                        &(cross_train_num['name_jaro_dis']<0.9)\n",
    "                        &(cross_train_num['name_jaro_dis']*cross_train_num['addr_jaro_dis']<0.4)\n",
    "                        &(cross_train_num['phone_jaro_dis']!=1)].index)\n",
    "    #blocking\n",
    "    def blocking(X):\n",
    "        df = pd.DataFrame(columns = X.columns)\n",
    "        for name in np.unique(X['id_x']):\n",
    "            df_p = X[X['id_x'] == name]\n",
    "            jaro_threshold = np.percentile(df_p['name_jaro_dis'], 15)\n",
    "            jaccard_threshold = np.percentile(df_p['name_jaccard_dis'], 85)\n",
    "            df_p = df_p[(df_p['name_jaro_dis'] > jaro_threshold) & (df_p['name_jaccard_dis'] <= jaccard_threshold)]\n",
    "            df = pd.concat([df, df_p])\n",
    "            df['missing_phone'] = df['missing_phone'].astype(int)\n",
    "            df['target'] = df['target'].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    features = ['name_jaro_dis','phone_jaro_dis','poscd_jaro_dis',\n",
    "                'addr_jaro_dis', 'loc_jaro_dis', 'lat_dis']\n",
    "    \n",
    "    train_blocking = blocking(cross_train_num)\n",
    "    X_train_blocking = train_blocking[features]\n",
    "    y_train_blocking = train_blocking[\"target\"]\n",
    "\n",
    "    #training\n",
    "    #use best parameters found from gridsearch\n",
    "    RF = RandomForestClassifier(random_state=0,class_weight='balanced',n_estimators=13,max_depth=12)\n",
    "    RF_pipeline = make_pipeline(Imputer(), RF)\n",
    "    RF_pipeline.fit(X_train_blocking, y_train_blocking)\n",
    "            \n",
    "    #preprocessing test set\n",
    "    locu_test = pd.read_json(locu_test_path)\n",
    "    foursquare_test = pd.read_json(foursquare_test_path)\n",
    "    matching_test = None\n",
    "    cross_test = preprocessing(locu_test, foursquare_test, matching_test)\n",
    "    X_test = cross_test[features]\n",
    "\n",
    "    #predicting\n",
    "    y_hat=pd.DataFrame(RF_pipeline.predict(X_test),columns=['target'])\n",
    "\n",
    "    matches_test = pd.concat([cross_test,y_hat],axis=1)\n",
    "    matches_test = matches_test[matches_test['target']==1][['id_x','id_y']]\n",
    "    matches_test.columns=['locu_id','foursquare_id']\n",
    "\n",
    "    matches_test.to_csv('matches_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shihhuayu/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/Users/shihhuayu/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/shihhuayu/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "get_matches(\"locu_train.json\",\"foursquare_train.json\",\"matches_train.csv\",\"locu_test.json\",\"foursquare_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
